{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4mVOW6NV8tyxx/l/OjLeS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alla-ud-din/Classes-Q3-Q4/blob/master/LangGraph/AGENTIC_PROJECTS/00_chat_agent_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Requirement Document: Agentic AI Chatbot Prototype 1**\n",
        "\n",
        "---\n",
        "\n",
        "#### **Objective:**\n",
        "Create a chatbot prototype that talks to users, remembers what they say during conversation, and helps them solve problems.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Project Requirements:**\n",
        "1. **Choose Your Niche:** Pick a specific group of people or industry to help with your chatbot (e.g., students, healthcare, customer service).\n",
        "\n",
        "2. **Make Smart Conversations:** Make sure the chatbot answers correctly and understands what users want. Use Prompt Engineering.\n",
        "\n",
        "3. **Add Useful Tools:** Give the chatbot features like helping users submit complaints, giving outfit ideas, or making study plans.\n",
        "\n",
        "4. **Short-Term Memory:** Make the chatbot remember the current conversation to give better answers.\n",
        "\n",
        "5. **Use Google Colab:** Build and test your chatbot using this platform.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Deliverables:**\n",
        "- A working chatbot prototype - Google Collab Link.\n",
        "- A list of tools and examples of how the chatbot can help people.\n",
        "\n",
        "---\n",
        "\n",
        "## **Submission Form**\n",
        "\n",
        "Submit your projects here:  \n",
        "[**Project Submission Form**](https://forms.gle/yB6X4TzE2dCVThCj8)\n",
        "\n",
        "---\n",
        "\n",
        "#### **User Stories:**\n",
        "- **As a student,** I want the chatbot to help me research & plan my study schedule, so I can prepare well for exams.\n",
        "- **As a customer,** I want the chatbot to help me file a complaint, so I can get my problem fixed quickly.\n",
        "- **As a partygoer,** I want the chatbot to give me outfit ideas, so I feel good and confident at the event.\n",
        "- **As a healthcare user,** I want the chatbot to answer simple health questions, so I can take care of myself better.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Competencies/Outcomes:**\n",
        "By completing this project, students will:\n",
        "\n",
        "1. **Basic Level - REACT Architecture:** Understand how to build an AI chatbot prototype.\n",
        "2. **Basic Level - Prompt Engineering:** Learn how to use prompt engineering for smart and relevant conversations.\n",
        "3. **Basic Level - Tool Calling & Chat Management:** Understand and demonstrating Tool Calling using LLMs.\n",
        "4. **Basic Level - Short-Term Memory:** Manage Chat Conversation s improve user interactions.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gT-vFiMrl2KH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU9nIgRiFzwO"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "ZAKddmjlGOWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=GEMINI_API_KEY\n",
        ")\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=2)\n",
        "# llm.invoke(\"greet me\")\n",
        "# tavily_search.invoke(\"What's a 'node' in LangGraph?\")"
      ],
      "metadata": {
        "id": "GYTnLIX1GU7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage, SystemMessage\n",
        "from IPython.display import Image, display, Markdown\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Define the State class to manage the state transitions\n",
        "class State(TypedDict):\n",
        "    user_query: Annotated[list[AnyMessage], add_messages]  # Stores user input messages\n",
        "    response: Annotated[list[AnyMessage], add_messages]  # Stores assistant responses\n",
        "\n",
        "# Initialize a state graph builder\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Define tool: Health Tips\n",
        "def health_tips(state: State) -> State:\n",
        "    \"\"\"Provide health tips using Tavily Search.\"\"\"\n",
        "    user_query = state['user_query'][-1].content  # Extract user query\n",
        "    tavily_response = tavily_search.invoke(user_query)  # Call Tavily Search API\n",
        "    print(\"Here are some health tips: \\n\")\n",
        "    return {\"response\": [AIMessage(content=tavily_response)]}  # Return the response\n",
        "\n",
        "# Define tool: Medical FAQs\n",
        "def medical_faqs(state: State) -> State:\n",
        "    \"\"\"Provide medical FAQs for a given condition using Tavily Search.\"\"\"\n",
        "    user_query = state['user_query'][-1].content  # Extract user query\n",
        "    query = f\"Medical FAQs about: {user_query}\"\n",
        "    tavily_response = tavily_search.invoke(query)  # Call Tavily Search API\n",
        "    print(\"Here are some FAQs: \\n\")\n",
        "    return {\"response\": [AIMessage(content=tavily_response)]}  # Return the response\n",
        "\n",
        "# Define tool: Medication Info\n",
        "def medication_info(state: State) -> State:\n",
        "    \"\"\"Provide information about medications.\"\"\"\n",
        "    user_query = state['user_query'][-1].content  # Extract user query\n",
        "    query = f\"Medication information for: {user_query}\"\n",
        "    tavily_response = tavily_search.invoke(query)  # Call Tavily Search API\n",
        "    print(\"Here is some information about the medication:\\n\")\n",
        "    return {\"response\": [AIMessage(content=tavily_response)]}  # Return the response\n",
        "\n",
        "# Define tool: General Query Handler\n",
        "def general_query_handler(state: State) -> State:\n",
        "    \"\"\"Handle general queries unrelated to medical topics.\"\"\"\n",
        "    user_query = state['user_query'][-1].content  # Extract user query\n",
        "    response = f\"It seems like your query is unrelated to medical topics. Here's a general response to '{user_query}': I'm here to help, but I specialize in health-related queries. Could you clarify or ask something health-related?\"\n",
        "    return {\"response\": [AIMessage(content=response)]}  # Return the response\n",
        "\n",
        "# List of tools\n",
        "tools = [health_tips, medical_faqs, medication_info, general_query_handler]\n",
        "\n",
        "# Bind tools to the LLM\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# Define a system message to guide the assistant\n",
        "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with helping user with their medical queries. Return tool call if user's query is related to any tool mentioned\")\n",
        "\n",
        "# Define the assistant node\n",
        "def assistant(state: State) -> State:\n",
        "    response = llm_with_tools.invoke([sys_msg] + state[\"user_query\"])  # Get response from the LLM\n",
        "    return {\"response\": [response]}  # Return the response\n",
        "\n",
        "# Define tool calling logic\n",
        "def tool_calling(state: State):\n",
        "    \"\"\"\n",
        "    Determine the next tool to call based on model responses.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if state['response'] and hasattr(state['response'][-1], 'tool_calls') and len(state['response'][-1].tool_calls) > 0:\n",
        "            tool_name = state['response'][-1].tool_calls[-1].get(\"name\", END)  # Extract tool name\n",
        "            return tool_name\n",
        "        return END  # End if no tool calls are present\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR in tool_calling]: {e}\")\n",
        "        return END  # End in case of error\n",
        "\n",
        "# Initialize the state graph builder\n",
        "builder: StateGraph = StateGraph(State)\n",
        "\n",
        "# Define nodes in the graph\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"health_tips\", health_tips)\n",
        "builder.add_node(\"medical_faqs\", medical_faqs)\n",
        "builder.add_node(\"medication_info\", medication_info)\n",
        "builder.add_node(\"general_query_handler\", general_query_handler)\n",
        "\n",
        "# Define edges in the graph\n",
        "builder.add_edge(START, \"assistant\")  # Start with the assistant node\n",
        "builder.add_conditional_edges(\"assistant\", tool_calling)  # Add conditional edges for tool calling\n",
        "builder.add_edge(\"health_tips\", END)  # End after health tips\n",
        "builder.add_edge(\"medical_faqs\", END)  # End after medical FAQs\n",
        "builder.add_edge(\"medication_info\", END)  # End after medication info\n",
        "builder.add_edge(\"general_query_handler\", END)  # End after general query handling\n",
        "\n",
        "# To save consersation in memory\n",
        "memory: MemorySaver = MemorySaver()\n",
        "# Compile the state graph\n",
        "graph: CompiledStateGraph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Visualize the graph\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2NFxg2BG610"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a thread configuration\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ],
      "metadata": {
        "id": "nyzNqaQkUvDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main interaction loop\n",
        "while True:\n",
        "    try:\n",
        "        # Get user input\n",
        "        user_input = input(\"Welcome to HealthHub! How can I assist you today? (type 'quit', 'exit', 'q' to exit): \")\n",
        "\n",
        "        # Exit loop if the user types 'quit', 'exit', or 'q'\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye! Stay healthy and take care!\")\n",
        "            break  # Exit loop if user wants to quit\n",
        "\n",
        "        # Invoke the workflow graph with the user's query\n",
        "        result = graph.invoke({\"user_query\": user_input}, config)\n",
        "\n",
        "        # Get the most recent message from the response\n",
        "        last_message = result[\"response\"][-1]\n",
        "\n",
        "        # Check if the message has 'content' and it is not empty\n",
        "        if hasattr(last_message, 'content') and last_message.content:\n",
        "            # Iterate over each response in the 'content' list\n",
        "            for response in last_message.content:\n",
        "                # Print the response in markdown format\n",
        "                print(f\"**HealthHub Response:**\\n\")\n",
        "                print(f\"### [Link to source]({response['url']})\\n\")  # Display the URL as a markdown link\n",
        "                print(f\"**Content:**\\n{response['content']}\\n\")  # Display the content\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any exceptions and print an error message\n",
        "        print(f\"[ERROR in main loop]: {e}\")\n",
        "        print(\"Bot: Sorry, something went wrong. Please try again.\")\n"
      ],
      "metadata": {
        "id": "g5F3xk_4Ta-I",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.values['user_query']"
      ],
      "metadata": {
        "id": "d6Ue-NVbTP2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.values['response'][-1].content"
      ],
      "metadata": {
        "id": "rVzuJY5niCRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}